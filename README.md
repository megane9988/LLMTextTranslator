# LLM Text Translator

A macOS menu bar application that provides real-time text translation and voice transcription using OpenAI's GPT and Whisper APIs.

## Features

### ğŸŒ Text Translation
- Translate selected text between English and Japanese automatically
- Uses OpenAI's GPT model for high-quality translations
- Quick access via keyboard shortcut
- Results displayed in floating popup windows
- Automatic clipboard copy of translation results

### ğŸ¤ Voice Recording & Transcription
- Record audio and convert speech to text using Whisper API
- Automatic filler word removal for cleaner transcriptions
- Support for Japanese language recognition
- Toggle recording with keyboard shortcut

### ğŸ“± Menu Bar Integration
- Lightweight menu bar app with globe icon (ğŸŒ)
- Test functions available through menu
- Clean, minimal interface

## System Requirements

- macOS 10.14 or later
- Microphone access for voice features
- Internet connection for API calls
- Valid OpenAI API key

## Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/megane9988/LLMTextTranslator.git
   cd LLMTextTranslator
   ```

2. Open `LLMTextTranslator.xcodeproj` in Xcode

3. Build and run the project

## Setup

### API Key Configuration

âš ï¸ **Important**: You need to configure your OpenAI API key before using the app.

Currently, the API key is hardcoded in the source code. For security reasons, you should:

1. Open `LLMTextTranslator/AppDelegate.swift`
2. Replace the hardcoded API key in both `callOpenAI` and `transcribeAudio` functions with your own key
3. Consider using environment variables or a secure configuration file instead

**Recommended**: Store your API key in an environment variable:
```swift
let apiKey = ProcessInfo.processInfo.environment["OPENAI_API_KEY"] ?? ""
```

### Permissions

The app requires the following permissions:

#### 1. Accessibility Permission
- Required for global keyboard shortcuts and text selection
- The app will prompt you to enable this in System Preferences
- Go to: System Preferences â†’ Security & Privacy â†’ Privacy â†’ Accessibility
- Add and enable "LLM Text Translator"

#### 2. Microphone Permission
- Required for voice recording features
- The app will request this permission automatically
- If denied, go to: System Preferences â†’ Security & Privacy â†’ Privacy â†’ Microphone
- Enable "LLM Text Translator"

## Usage

### Text Translation

1. Select any text in any application
2. Press `âŒ˜ + âŒ¥ + â‡§ + T`
3. The selected text will be copied and translated
4. Translation result appears in a floating popup window
5. The result is automatically copied to your clipboard

**Note**: The app automatically detects the language and translates between English and Japanese.

### Voice Recording

1. Press `âŒ˜ + âŒ¥ + â‡§ + R` to start recording
2. Speak into your microphone
3. Press the same shortcut again to stop recording
4. The transcribed text will appear in a floating popup window
5. The result is automatically copied to your clipboard

### Menu Bar Options

Click the globe icon (ğŸŒ) in your menu bar to access:
- **Test Translation**: Test the translation feature
- **Test Recording**: Test the recording feature
- **Quit**: Exit the application

## Keyboard Shortcuts

| Shortcut | Function |
|----------|----------|
| `âŒ˜ + âŒ¥ + â‡§ + T` | Translate selected text |
| `âŒ˜ + âŒ¥ + â‡§ + R` | Toggle voice recording |

## Troubleshooting

### "Accessibility permission required" message
- Go to System Preferences â†’ Security & Privacy â†’ Privacy â†’ Accessibility
- Click the lock icon and enter your password
- Add "LLM Text Translator" to the list and check the box

### "Microphone permission required" message
- Go to System Preferences â†’ Security & Privacy â†’ Privacy â†’ Microphone
- Add "LLM Text Translator" to the list and check the box

### Translation not working
- Ensure you have a valid OpenAI API key configured
- Check your internet connection
- Verify that text is properly selected before using the shortcut

### Recording not working
- Check microphone permissions
- Ensure your microphone is working in other applications
- Verify OpenAI API key is configured

### API Error Messages
- "Network Error": Check your internet connection
- "Invalid API Key": Verify your OpenAI API key is correct and has sufficient credits

## Development

### Project Structure
```
LLMTextTranslator/
â”œâ”€â”€ AppDelegate.swift          # Main application logic
â”œâ”€â”€ LLMTextTranslatorApp.swift # App entry point
â”œâ”€â”€ ContentView.swift          # SwiftUI view (minimal)
â”œâ”€â”€ Info.plist                 # App configuration
â””â”€â”€ LLMTextTranslator.entitlements # Security entitlements
```

### Key Components

- **AppDelegate.swift**: Contains all the main functionality including API calls, recording, and UI management
- **Menu Bar Integration**: Uses `NSStatusItem` for menu bar presence
- **Global Shortcuts**: Implemented using `NSEvent.addGlobalMonitorForEvents`
- **API Integration**: Direct HTTP calls to OpenAI's APIs
- **Permissions**: Handles accessibility and microphone permissions

### Building from Source

1. Ensure you have Xcode installed
2. Open the project in Xcode
3. Configure your development team in project settings
4. Build and run

## Security Notes

- The app requires accessibility permissions to monitor global keystrokes
- Microphone access is needed for voice recording
- API keys should be stored securely, not hardcoded
- The app runs as a background menu bar application

## License

Copyright Â© 2025 9988 megane. All rights reserved.

## Contributing

This project uses OpenAI's APIs for translation and transcription. Make sure you have appropriate API access and understand OpenAI's usage policies.

---

**Note**: This app is designed for personal use and development purposes. Ensure you comply with OpenAI's terms of service and usage policies when using their APIs.

---

## æ—¥æœ¬èªç‰ˆèª¬æ˜ (Japanese Documentation)

### æ¦‚è¦
LLM Text Translatorã¯ã€OpenAIã®GPTã¨Whisper APIã‚’ä½¿ç”¨ã—ã¦ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³ã¨éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’è¡Œã†macOSãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚

### ä¸»ãªæ©Ÿèƒ½
- **ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³**: é¸æŠã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è‹±èªã¨æ—¥æœ¬èªé–“ã§è‡ªå‹•ç¿»è¨³
- **éŸ³å£°éŒ²éŸ³ãƒ»æ–‡å­—èµ·ã“ã—**: éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ï¼ˆãƒ•ã‚£ãƒ©ãƒ¼éŸ³é™¤å»æ©Ÿèƒ½ä»˜ãï¼‰
- **ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼çµ±åˆ**: è»½é‡ã§ä½¿ã„ã‚„ã™ã„ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã‚¢ãƒ—ãƒª

### ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
- `âŒ˜ + âŒ¥ + â‡§ + T`: é¸æŠã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³
- `âŒ˜ + âŒ¥ + â‡§ + R`: éŸ³å£°éŒ²éŸ³ã®é–‹å§‹/åœæ­¢

### å¿…è¦ãªæ¨©é™
1. **ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£æ¨©é™**: ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š â†’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ â†’ ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ â†’ ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£
2. **ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³æ¨©é™**: ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š â†’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ â†’ ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ â†’ ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³

### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
1. OpenAI APIã‚­ãƒ¼ã‚’å–å¾—
2. `AppDelegate.swift`å†…ã®APIã‚­ãƒ¼ã‚’è‡ªåˆ†ã®ã‚­ãƒ¼ã«ç½®ãæ›ãˆ
3. ã‚¢ãƒ—ãƒªã‚’ãƒ“ãƒ«ãƒ‰ã—ã¦å®Ÿè¡Œ

è©³ç´°ã«ã¤ã„ã¦ã¯ä¸Šè¨˜ã®è‹±èªç‰ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã”å‚ç…§ãã ã•ã„ã€‚